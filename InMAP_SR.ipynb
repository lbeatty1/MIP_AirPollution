{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbeatty\\AppData\\Local\\Temp\\ipykernel_7568\\3896552863.py:11: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "globals().clear()\n",
    "\n",
    "\n",
    "from __future__ import (absolute_import, division, print_function, unicode_literals)\n",
    "from builtins import * \n",
    "from io import BytesIO, TextIOWrapper\n",
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "import csv\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import zarr\n",
    "from shapely.geometry import Polygon, Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import s3fs\n",
    "import os\n",
    "\n",
    "\n",
    "os.chdir('C:/Users/lbeatty/Documents/Lauren_MIP_Contribution/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect(i, w, s, e, n):\n",
    "    x = [w[i], e[i], e[i], w[i], w[i]]\n",
    "    y = [s[i], s[i], n[i], n[i], s[i]]\n",
    "    return x, y\n",
    "\n",
    "def poly(sr):\n",
    "    ret = []\n",
    "    w = sr[\"W\"][:]\n",
    "    s = sr[\"S\"][:]\n",
    "    e = sr[\"E\"][:]\n",
    "    n = sr[\"N\"][:]\n",
    "    for i in range(52411):\n",
    "        x, y = rect(i, w, s, e, n)\n",
    "        ret.append(Polygon([[x[0],y[0]],[x[1],y[1]],[x[2],y[2]],\n",
    "                            [x[3],y[3]],[x[4],y[4]]]))\n",
    "    return ret\n",
    "\n",
    "def run_sr(emis, model, emis_units=\"tons/year\"):\n",
    "    start = time.time()\n",
    "    url = 's3://inmap-model/isrm_v1.2.1.zarr/'\n",
    "    fs = s3fs.S3FileSystem(anon=True, client_kwargs=dict(region_name='us-east-2'))\n",
    "    sr = zarr.open(s3fs.S3Map(url, s3=fs, check=False), mode=\"r\")\n",
    "#     the following line is used when we access the SR matrix from local files\n",
    "#     sr = zarr.open(\"isrm_v1.2.1.zarr\", mode=\"r\")\n",
    "\n",
    "    # build the geometry\n",
    "    p = poly(sr)\n",
    "    print(\"Making polygons as geometry.\")\n",
    "\n",
    "    # took the emis geopandas dataframe\n",
    "    df = pd.DataFrame({'Location': range(52411)})\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=p)\n",
    "\n",
    "    # join the emis dataframe into the grid dataframe\n",
    "    emis.crs = \"+proj=longlat\"\n",
    "    gdf.crs = \"+proj=lcc +lat_1=33.000000 +lat_2=45.000000 +lat_0=40.000000 +lon_0=-97.000000 +x_0=0 +y_0=0 +a=6370997.000000 +b=6370997.000000 +to_meter=1\"\n",
    "    emis = emis.to_crs(gdf.crs)\n",
    "    join_right_df = gdf.sjoin(emis, how=\"right\")\n",
    "    print(\"Finished joining the dataframes.\")\n",
    "    \n",
    "    index = join_right_df.Location.tolist()\n",
    "\n",
    "    ppl = np.unique(join_right_df.Location.tolist())\n",
    "\n",
    "    num = range(0,len(ppl))\n",
    "\n",
    "    dictionary = dict(zip(ppl, num))\n",
    "        \n",
    "    SOA = sr['SOA'].get_orthogonal_selection(([0], ppl, slice(None)))\n",
    "    print(\"SOA data is allocated.\")\n",
    "    pNO3 = sr['pNO3'].get_orthogonal_selection(([0], ppl, slice(None)))\n",
    "    print(\"pNO3 data is allocated.\")\n",
    "    pNH4 = sr['pNH4'].get_orthogonal_selection(([0], ppl, slice(None)))\n",
    "    print(\"pNH4 data is allocated.\")\n",
    "    pSO4 = sr['pSO4'].get_orthogonal_selection(([0], ppl, slice(None)))\n",
    "    print(\"pSO4 data is allocated.\")\n",
    "    PM25 = sr['PrimaryPM25'].get_orthogonal_selection(([0], ppl, slice(None)))\n",
    "    print(\"PrimaryPM25 data is allocated.\")\n",
    "    \n",
    "    SOA_data, pNO3_data, pNH4_data, pSO4_data, PM25_data = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    for i in range(len(index)):\n",
    "        SOA_data += SOA[0, dictionary[index[i]], :]*emis.VOC[i]\n",
    "        pNO3_data += pNO3[0, dictionary[index[i]], :]*emis.NOx[i]\n",
    "        pNH4_data += pNH4[0, dictionary[index[i]], :]*emis.NH3[i]\n",
    "        pSO4_data += pSO4[0, dictionary[index[i]], :]*emis.SOx[i]\n",
    "        PM25_data += PM25[0, dictionary[index[i]], :]*emis.PM2_5[i]\n",
    "    data = SOA_data + pNO3_data + pNH4_data + pSO4_data + PM25_data\n",
    "\n",
    "    print(\"Accessing the data.\")\n",
    "    if emis_units==\"tons/year\":\n",
    "        fact = 28766.639\n",
    "\n",
    "    TotalPM25 = fact * data\n",
    "    TotalPop = sr['TotalPop'][0:52411]\n",
    "    MortalityRate = sr['MortalityRate'][0:52411]\n",
    "    Asian = sr['Asian'][0:52411]\n",
    "    Black = sr['Black'][0:52411]\n",
    "    Native = sr['Native'][0:52411]\n",
    "    Latino = sr['Latino'][0:52411]\n",
    "    WhiteNoLat = sr['WhiteNoLat'][0:52411]\n",
    "    deathsK = (np.exp(np.log(1.06)/10 * TotalPM25) - 1) * TotalPop * 1.07353545 * MortalityRate / 100000 * 1.025229357798165\n",
    "    deathsL = (np.exp(np.log(1.14)/10 * TotalPM25) - 1) * TotalPop * 1.07353545 * MortalityRate / 100000 * 1.025229357798165\n",
    "\n",
    "    AsiandeathsK = (np.exp(np.log(1.06)/10 * TotalPM25) - 1) * Asian * 1.07353545 * MortalityRate / 100000 * 1.025229357798165\n",
    "    AsiandeathsL = (np.exp(np.log(1.14)/10 * TotalPM25) - 1) * Asian * 1.07353545 * MortalityRate / 100000 * 1.025229357798165\n",
    "\n",
    "    BlackdeathsK = (np.exp(np.log(1.06)/10 * TotalPM25) - 1) * Black * 1.07353545 * MortalityRate / 100000 * 1.025229357798165\n",
    "    BlackdeathsL = (np.exp(np.log(1.14)/10 * TotalPM25) - 1) * Black * 1.07353545 * MortalityRate / 100000 * 1.025229357798165\n",
    "    \n",
    "    NativedeathsK = (np.exp(np.log(1.06)/10 * TotalPM25) - 1) * Native * 1.07353545 * MortalityRate / 100000 * 1.025229357798165\n",
    "    NativedeathsL = (np.exp(np.log(1.14)/10 * TotalPM25) - 1) * Native * 1.07353545 * MortalityRate / 100000 * 1.025229357798165\n",
    "    \n",
    "    LatinodeathsK = (np.exp(np.log(1.06)/10 * TotalPM25) - 1) * Latino * 1.07353545 * MortalityRate / 100000 * 1.025229357798165\n",
    "    LatinodeathsL = (np.exp(np.log(1.14)/10 * TotalPM25) - 1) * Latino * 1.07353545 * MortalityRate / 100000 * 1.025229357798165\n",
    "\n",
    "    WhiteNoLatdeathsK = (np.exp(np.log(1.06)/10 * TotalPM25) - 1) * WhiteNoLat * 1.07353545 * MortalityRate / 100000 * 1.025229357798165\n",
    "    WhiteNoLatdeathsL = (np.exp(np.log(1.14)/10 * TotalPM25) - 1) * WhiteNoLat * 1.07353545 * MortalityRate / 100000 * 1.025229357798165\n",
    "    #1.07353545 is the ratio of 2020 population to 2010 population (in the model)\n",
    "    #1.025229357798165 is the ratio of 2016 mortality rate to 2005 (but I'm going to keep this since 2020 was likely an abnormal deaths years)\n",
    "    ret = gpd.GeoDataFrame(pd.DataFrame({'SOA': fact * SOA_data,\n",
    "                                         'pNO3': fact * pNO3_data,\n",
    "                                         'pNH4': fact * pNH4_data,\n",
    "                                         'pSO4': fact * pSO4_data,\n",
    "                                         'PrimaryPM25': fact * PM25_data,\n",
    "                                         'TotalPM25': TotalPM25,\n",
    "                                         'deathsK': deathsK,\n",
    "                                         'deathsL': deathsL,\n",
    "                                         'Black' : Black,\n",
    "                                         'Asian' : Asian,\n",
    "                                         'WhiteNoLat' : WhiteNoLat,\n",
    "                                         'Native' : Native,\n",
    "                                         'Latino' : Latino,\n",
    "                                         'AsiandeathsK' : AsiandeathsK,\n",
    "                                         'AsiandeathsL' : AsiandeathsL,\n",
    "                                         'BlackdeathsK' : BlackdeathsK,\n",
    "                                         'BlackdeathsL' : BlackdeathsL,\n",
    "                                         'LatinodeathsK' : LatinodeathsK,\n",
    "                                         'LatinodeathsL' : LatinodeathsL,\n",
    "                                         'NativedeathsK' : NativedeathsK,\n",
    "                                         'NativedeathsL' : NativedeathsL,\n",
    "                                         'WhiteNoLatdeathsK' : WhiteNoLatdeathsK,\n",
    "                                         'WhiteNoLatdeathsL' : WhiteNoLatdeathsL}), geometry=p[0:52411])\n",
    "\n",
    "    print(\"Finished (%.0f seconds)               \"%(time.time()-start))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbeatty\\AppData\\Local\\Temp\\ipykernel_7568\\3442910910.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  print(emis.sum())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude    -88.0103-88.0103-88.0103-88.0103-88.0103-88.01...\n",
      "Latitude     31.006931.006931.006931.006931.006931.006931.0...\n",
      "NOx                                              770928.321827\n",
      "SOx                                              742892.339769\n",
      "PM2_5                                             95545.679707\n",
      "VOC                                               22853.854935\n",
      "NH3                                               33691.454319\n",
      "dtype: object\n",
      "Making polygons as geometry.\n",
      "Finished joining the dataframes.\n",
      "SOA data is allocated.\n",
      "pNO3 data is allocated.\n",
      "pNH4 data is allocated.\n",
      "pSO4 data is allocated.\n",
      "PrimaryPM25 data is allocated.\n",
      "Accessing the data.\n",
      "Finished (1662 seconds)               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbeatty\\AppData\\Local\\Temp\\ipykernel_7568\\3442910910.py:13: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  resultsISRM.to_file(filename='InMap/MIP_InMap_Output/'+scenario+'/'+model+'/ISRM_result_'+year+'.shp', driver='ESRI Shapefile')\n",
      "C:\\Users\\lbeatty\\AppData\\Local\\Temp\\ipykernel_7568\\3442910910.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  print(emis.sum())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude    -84.1103-89.629722-71.17527800000001-82.396388...\n",
      "Latitude     31.555944.88777844.47194429.767531.83213243.08...\n",
      "NOx                                               58943.296325\n",
      "SOx                                                5937.448899\n",
      "PM2_5                                             22605.804052\n",
      "VOC                                                5413.071737\n",
      "NH3                                               12099.665461\n",
      "dtype: object\n",
      "Making polygons as geometry.\n",
      "Finished joining the dataframes.\n"
     ]
    }
   ],
   "source": [
    "#scenario = '26z-short-current-policies'\n",
    "scenario = '26z-short-base-200'\n",
    "model = 'GenX'\n",
    "\n",
    "years = ['2020', '2030', '2040', '2050']\n",
    "\n",
    "for year in years:\n",
    "    emis = gpd.read_file('InMap/MIP_Emissions/'+scenario+'/'+model+'/emissions_'+year+'.shp')\n",
    "    print(emis.sum())\n",
    "    resultsISRM = run_sr(emis, model=\"isrm\")\n",
    "    resultsISRM = resultsISRM.set_crs('PROJCS[\"Lambert_Conformal_Conic\",GEOGCS[\"GCS_unnamed ellipse\",DATUM[\"D_unknown\",SPHEROID[\"Unknown\",6370997,0]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Lambert_Conformal_Conic_2SP\"],PARAMETER[\"latitude_of_origin\",40],PARAMETER[\"central_meridian\",-97],PARAMETER[\"standard_parallel_1\",33],PARAMETER[\"standard_parallel_2\",45],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]')\n",
    "\n",
    "    resultsISRM.to_file(filename='InMap/MIP_InMap_Output/'+scenario+'/'+model+'/ISRM_result_'+year+'.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJCS[\"Lambert_Conformal_Conic\",GEOGCS[\"GCS_unnamed ellipse\",DATUM[\"D_unknown\",SPHEROID[\"Unknown\",6370997,0]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Lambert_Conformal_Conic_2SP\"],PARAMETER[\"latitude_of_origin\",40],PARAMETER[\"central_meridian\",-97],PARAMETER[\"standard_parallel_1\",33],PARAMETER[\"standard_parallel_2\",45],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n"
     ]
    }
   ],
   "source": [
    "print(resultsISRM.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SOA      pNO3     pNH4     pSO4  PrimaryPM25  TotalPM25  deathsK  \\\n",
      "0  0.000019  0.000052  0.00014  0.00002     0.000142   0.000372      0.0   \n",
      "1  0.000019  0.000052  0.00014  0.00002     0.000142   0.000372      0.0   \n",
      "2  0.000019  0.000052  0.00014  0.00002     0.000142   0.000372      0.0   \n",
      "3  0.000019  0.000052  0.00014  0.00002     0.000142   0.000372      0.0   \n",
      "4  0.000019  0.000052  0.00014  0.00002     0.000142   0.000372      0.0   \n",
      "\n",
      "   deathsL                                           geometry  \n",
      "0      0.0  POLYGON ((-2736000.000 -2088000.000, -2688000....  \n",
      "1      0.0  POLYGON ((-2736000.000 -2040000.000, -2688000....  \n",
      "2      0.0  POLYGON ((-2736000.000 -1992000.000, -2688000....  \n",
      "3      0.0  POLYGON ((-2736000.000 -1944000.000, -2688000....  \n",
      "4      0.0  POLYGON ((-2736000.000 -1896000.000, -2688000....  \n",
      "  Model  Krewski Deaths  LePeule Deaths\n",
      "0  ISRM     2107.930655      4752.92214\n"
     ]
    }
   ],
   "source": [
    "print(resultsISRM.head())\n",
    "\n",
    "deaths = pd.DataFrame.from_dict({\n",
    "    \"Model\": [\"ISRM\"],\n",
    "    \"Krewski Deaths\": [resultsISRM.deathsK.sum()],\n",
    "    \"LePeule Deaths\": [resultsISRM.deathsL.sum()],\n",
    "})\n",
    "\n",
    "print(deaths)\n",
    "\n",
    "ISRM_dataframe = pd.DataFrame(resultsISRM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
