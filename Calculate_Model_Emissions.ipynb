{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to impute emissions rates, then take model output and generate total emissions by year\n",
    "The first challenge will be to get emissions rates (lb/mwh).  To do this I'll be taking EIA data on net generation and EPA data on emissions to calculate rates.  There will be many missings that I will fill in by taking generation-weighted technology-planning_year means.\n",
    "\n",
    "Once I have emissions rates, the goal will be to output a series of shapefiles of location-specific aggregate emissions by year. A challenge here is taking production from the scenario outputs and assigning it to specific plants.  There are two reasonable ways of doing this -- either with net generation or capacity.  I let the user select which variable they want to use.\n",
    "\n",
    "### Brief Code Overview\n",
    "1. Data cleaning (formatting columns, names, etc)\n",
    "2. Merge EIA and EPA data into existing_gen_units using the EPA-EIA crosswalk\n",
    "3. Impute generation for generators with missing generation.  To do this, I take plant-level generation and distribute that generation to generators based on each generator's capacity.\n",
    "4. Calculate generation-weighted average emissions rates, then use those to fill in generators with missing emissions rates (missings get filled in with a technology-planningyear weighted mean).\n",
    "5. Calculate aggregate emissions by multiplying rates by model-output specified generation.  As mentioned earlier, I calculate generator level generation either by calculating a generator's share of total capacity or net generation for that cluster-planningyear.\n",
    "6. Split the emissions output by planning year and write to shapefiles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lbeatty\\AppData\\Local\\miniconda3\\envs\\powergenome\\lib\\site-packages\\geopandas\\_compat.py:123: UserWarning: The Shapely GEOS version (3.11.2-CAPI-1.17.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.3-CAPI-1.16.1). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lbeatty\\AppData\\Local\\Temp\\ipykernel_15524\\1104421519.py:7: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas\n"
     ]
    }
   ],
   "source": [
    "globals().clear()\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbeatty\\AppData\\Local\\Temp\\ipykernel_15524\\3930867010.py:5: DtypeWarning: Columns (13,17,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_gen_units_2030 = pd.read_csv('MIP_results_comparison/case_settings/26-zone/usensys_inputs_10_weeks/2030/existing_gen_units.csv')\n",
      "C:\\Users\\lbeatty\\AppData\\Local\\Temp\\ipykernel_15524\\3930867010.py:6: DtypeWarning: Columns (13,16,17,18,19,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_gen_units_2040 = pd.read_csv('MIP_results_comparison/case_settings/26-zone/usensys_inputs_10_weeks/2040/existing_gen_units.csv')\n"
     ]
    }
   ],
   "source": [
    "os.chdir('C:/Users/lbeatty/Documents/Lauren_MIP_Contribution/')\n",
    "\n",
    "\n",
    "#PG existing gen units output\n",
    "existing_gen_units_2030 = pd.read_csv('MIP_results_comparison/case_settings/26-zone/usensys_inputs_10_weeks/2030/existing_gen_units.csv')\n",
    "existing_gen_units_2040 = pd.read_csv('MIP_results_comparison/case_settings/26-zone/usensys_inputs_10_weeks/2040/existing_gen_units.csv')\n",
    "existing_gen_units_2050 = pd.read_csv('MIP_results_comparison/case_settings/26-zone/usensys_inputs_10_weeks/2050/existing_gen_units.csv')\n",
    "\n",
    "#EIA-EPA Crosswalk\n",
    "crosswalk = pd.read_csv(\"Data/epa_eia_crosswalk.csv\")\n",
    "\n",
    "# EIA 860 for Generator Info\n",
    "eia860 = pd.read_excel(\"Data/eia860/3_1_Generator_Y2020.xlsx\", skiprows=1)\n",
    "\n",
    "# EIA923 for Generation Info\n",
    "eia923_fuels = pd.read_excel(\"Data/eia923/EIA923_Schedules_2_3_4_5_M_12_2020_Final_Revision.xlsx\", sheet_name='Page 1 Generation and Fuel Data', skiprows=5)\n",
    "eia923_generators = pd.read_excel(\"Data/eia923/EIA923_Schedules_2_3_4_5_M_12_2020_Final_Revision.xlsx\", sheet_name='Page 4 Generator Data', skiprows=5)\n",
    "\n",
    "#Emissions\n",
    "emissions = pd.read_csv(\"Data/CAMD/facilities_emissions.csv\")\n",
    "#only want year 2020\n",
    "emissions = emissions.query('year==2020')\n",
    "\n",
    "# PM25\n",
    "pm25 = pd.read_excel(\"Data/eGRID2020 DRAFT PM Emissions.xlsx\", sheet_name=\"2020 PM Unit-level Data\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "## Format columns ###\n",
    "#####################\n",
    "\n",
    "# existing_gen_units\n",
    "existing_gen_units_2030['plant_id_eia']=existing_gen_units_2030['plant_id_eia'].astype(int)\n",
    "existing_gen_units_2040['plant_id_eia']=existing_gen_units_2040['plant_id_eia'].astype(int)\n",
    "existing_gen_units_2050['plant_id_eia']=existing_gen_units_2050['plant_id_eia'].astype(int)\n",
    "\n",
    "existing_gen_units_2030['generator_id']=existing_gen_units_2030['generator_id'].astype(str)\n",
    "existing_gen_units_2040['generator_id']=existing_gen_units_2040['generator_id'].astype(str)\n",
    "existing_gen_units_2050['generator_id']=existing_gen_units_2050['generator_id'].astype(str)\n",
    "\n",
    "existing_gen_units_2030['planning_year']=2030\n",
    "existing_gen_units_2040['planning_year']=2040\n",
    "existing_gen_units_2050['planning_year']=2050\n",
    "\n",
    "#bind all into one\n",
    "existing_gen_units = pd.concat([existing_gen_units_2030, existing_gen_units_2040, existing_gen_units_2050])\n",
    "existing_gen_units = existing_gen_units.rename(columns={'generator_id': 'EIA_GENERATOR_ID', 'plant_id_eia':'EIA_PLANT_ID'})\n",
    "\n",
    "\n",
    "## EPA-EIA crosswalk\n",
    "crosswalk = crosswalk[['CAMD_PLANT_ID', 'CAMD_UNIT_ID', 'CAMD_GENERATOR_ID', 'EIA_PLANT_ID', 'EIA_GENERATOR_ID', 'EIA_UNIT_TYPE']]\n",
    "crosswalk['EIA_GENERATOR_ID'] = crosswalk['EIA_GENERATOR_ID'].astype(str)\n",
    "\n",
    "\n",
    "## EIA Data\n",
    "eia860 = eia860[['Plant Code', 'Generator ID', 'Nameplate Capacity (MW)', 'Planned Retirement Year', 'Planned Retirement Month', 'Synchronized to Transmission Grid', 'Technology']]\n",
    "eia860.columns = ['EIA_PLANT_ID', 'EIA_GENERATOR_ID', 'Capacity', 'RetirementYear', 'RetirementMonth', 'SynchronizedToGrid', 'Technology']\n",
    "eia860['EIA_GENERATOR_ID']=eia860['EIA_GENERATOR_ID'].astype(str)\n",
    "\n",
    "eia923_fuels = eia923_fuels[['Plant Id', 'Plant Name', 'Plant State', 'Net Generation\\n(Megawatthours)']]\n",
    "eia923_fuels.columns = ['EIA_PLANT_ID', 'EIA_PLANT_NAME', 'EIA_STATE', 'NET_GEN_PLANT']\n",
    "eia923_fuels = eia923_fuels.groupby('EIA_PLANT_ID').agg({'NET_GEN_PLANT': 'sum'}).reset_index()\n",
    "\n",
    "eia923_generators = eia923_generators[['Plant Id', 'Generator Id', 'Net Generation\\nYear To Date']]\n",
    "eia923_generators.columns = ['EIA_PLANT_ID', 'EIA_GENERATOR_ID', 'NET_GEN_GENERATOR']\n",
    "eia923_generators['EIA_GENERATOR_ID'] = eia923_generators['EIA_GENERATOR_ID'].astype(str)\n",
    "\n",
    "pm25['UNITID'] = pm25['UNITID'].astype(str)\n",
    "pm25 = pm25.groupby(['ORISPL', 'UNITID']).agg({'PM25AN': 'sum'}).reset_index()\n",
    "pm25.columns = ['facilityId', 'unitId', 'pm25']\n",
    "pm25['unitId']=pm25['unitId'].astype(str)\n",
    "pm25['facilityId']=pm25['facilityId'].astype(int)\n",
    "\n",
    "emissions['unitId']=emissions['unitId'].astype(str)\n",
    "emissions['facilityId']=emissions['facilityId'].astype(int)\n",
    "\n",
    "#Get emissions in pounds\n",
    "emissions = pd.merge(emissions, pm25, on=['facilityId', 'unitId'], how='left')\n",
    "emissions['nox_lbs'] = emissions['noxMass'] * 2000\n",
    "emissions['so2_lbs'] = emissions['so2Mass'] * 2000\n",
    "emissions['pm25_lbs'] = emissions['pm25'] * 2000\n",
    "\n",
    "#rename columns\n",
    "emissions = emissions.rename(columns = {'facilityId': 'CAMD_PLANT_ID', 'unitId': 'CAMD_UNIT_ID'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merge EIA and EPA data into existing_gen_units using the EPA-EIA crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join existing_gen_units with crosswalk\n",
    "existing_gen_units = pd.merge(existing_gen_units, crosswalk, on=['EIA_GENERATOR_ID', 'EIA_PLANT_ID'],how='left')\n",
    "\n",
    "#in existing_gen_units, there's a fair amount of missing capacities that are available from eia data so I'm going to join in \n",
    "#eia860 and then fill in nans\n",
    "existing_gen_units = pd.merge(existing_gen_units, eia860[['EIA_GENERATOR_ID', 'EIA_PLANT_ID', 'Capacity']], on=['EIA_GENERATOR_ID', 'EIA_PLANT_ID'], how='left')\n",
    "\n",
    "#need net gen\n",
    "existing_gen_units = pd.merge(existing_gen_units, eia923_fuels, on=['EIA_PLANT_ID'], how='left')\n",
    "existing_gen_units = pd.merge(existing_gen_units, eia923_generators, on=['EIA_PLANT_ID', 'EIA_GENERATOR_ID'], how='left')\n",
    "\n",
    "#lastly, need emissions\n",
    "existing_gen_units = pd.merge(existing_gen_units, emissions, on=['CAMD_PLANT_ID', 'CAMD_UNIT_ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in missing capacities\n",
    "existing_gen_units['capacity_mw']=existing_gen_units['capacity_mw'].combine_first(existing_gen_units['Capacity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Impute generation for generators with missing generation.  To do this, I take plant-level generation and distribute that generation to generators based on each generator's capacity.\n",
    "\n",
    "I'm going to calculate plant-level 'missing generation'\n",
    "Then divy up the missing generation to generators according to capacity in MW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_plant_gen = existing_gen_units.groupby(['EIA_PLANT_ID', 'planning_year']).agg({'NET_GEN_GENERATOR': 'sum'}).reset_index()\n",
    "summed_plant_gen.columns=['EIA_PLANT_ID', 'planning_year', 'sum_generator_gen']\n",
    "\n",
    "existing_gen_units = pd.merge(existing_gen_units, summed_plant_gen, on=['EIA_PLANT_ID', 'planning_year'], how='left')\n",
    "\n",
    "existing_gen_units['missing_generator_generation']=existing_gen_units['NET_GEN_GENERATOR'].isna().astype(int)\n",
    "existing_gen_units['missing_generation'] = existing_gen_units['NET_GEN_PLANT'] - existing_gen_units['sum_generator_gen']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_generators = existing_gen_units.query('missing_generator_generation==1').\\\n",
    "    groupby(['EIA_PLANT_ID', 'planning_year']).\\\n",
    "    agg({'capacity_mw': 'sum'}).\\\n",
    "    reset_index()\n",
    "missing_generators.columns=['EIA_PLANT_ID', 'planning_year', 'missing_generator_capacity']\n",
    "\n",
    "existing_gen_units = pd.merge(existing_gen_units, missing_generators, on=['EIA_PLANT_ID', 'planning_year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make imputation\n",
    "\n",
    "existing_gen_units['pct_missing_capacity'] = (existing_gen_units['capacity_mw']/existing_gen_units['missing_generator_capacity'])*existing_gen_units['missing_generator_generation']\n",
    "existing_gen_units['imputed_net_gen'] = existing_gen_units['pct_missing_capacity']*existing_gen_units['missing_generation']\n",
    "\n",
    "\n",
    "#replace missings with imputed\n",
    "existing_gen_units['NET_GEN_GENERATOR'] = existing_gen_units['NET_GEN_GENERATOR'].combine_first(existing_gen_units['imputed_net_gen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate generation-weighted average emissions rates, then use those to fill in generators with missing emissions rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rates\n",
    "existing_gen_units['nox_rate'] = existing_gen_units['nox_lbs']/existing_gen_units['NET_GEN_GENERATOR']\n",
    "existing_gen_units['so2_rate'] = existing_gen_units['so2_lbs']/existing_gen_units['NET_GEN_GENERATOR']\n",
    "existing_gen_units['pm25_rate'] = existing_gen_units['pm25_lbs']/existing_gen_units['NET_GEN_GENERATOR']\n",
    "\n",
    "#for now I'm going to omit units with negative net_gen since it doesn't make sense for them to have negative 'rates'\n",
    "#I'll replace the rates with sample weighted-means\n",
    "existing_gen_units.loc[existing_gen_units['nox_rate']<0, 'nox_rate']=np.nan\n",
    "existing_gen_units.loc[existing_gen_units['pm25_rate']<0, 'pm25_rate']=np.nan\n",
    "existing_gen_units.loc[existing_gen_units['so2_rate']<0, 'so2_rate']=np.nan\n",
    "\n",
    "existing_gen_units.loc[existing_gen_units['nox_rate'].isin([np.inf]), 'nox_rate']=np.nan\n",
    "existing_gen_units.loc[existing_gen_units['pm25_rate'].isin([np.inf]), 'pm25_rate']=np.nan\n",
    "existing_gen_units.loc[existing_gen_units['so2_rate'].isin([np.inf]), 'so2_rate']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## Calculate weighted average emissions rates by technology-planning year\n",
    "\n",
    "# Define a function to calculate weighted average handling NaN values\n",
    "\n",
    "def weighted_average(df):\n",
    "    weighted_avgs = {}\n",
    "    for col in df.columns:\n",
    "        if '_rate' in col:  # Consider columns containing '_rate'\n",
    "            df_valid = df.dropna(subset=[col, 'NET_GEN_GENERATOR'])\n",
    "            if len(df_valid) == 0 or df_valid['NET_GEN_GENERATOR'].sum() == 0:\n",
    "                weighted_avgs[col] = np.nan  # Return NaN if all weights in the group are zero\n",
    "            else:\n",
    "                weighted_avgs[col] = np.average(df_valid[col], weights=df_valid['NET_GEN_GENERATOR'])\n",
    "    return pd.Series(weighted_avgs)\n",
    "\n",
    "technology_rates = existing_gen_units.groupby(['technology', 'planning_year']).apply(weighted_average).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok last thing to do is fill in missings\n",
    "\n",
    "technology_rates = technology_rates[['technology', 'planning_year', 'nox_rate', 'pm25_rate', 'so2_rate']]\n",
    "technology_rates.columns = ['technology', 'planning_year', 'noxrate_imputed', 'pm25rate_imputed', 'so2rate_imputed']\n",
    "\n",
    "existing_gen_units = pd.merge(existing_gen_units, technology_rates, on=['technology', 'planning_year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_gen_units['noxrate_imputed'] = existing_gen_units['nox_rate'].combine_first(existing_gen_units['noxrate_imputed'])\n",
    "existing_gen_units['so2rate_imputed'] = existing_gen_units['so2_rate'].combine_first(existing_gen_units['so2rate_imputed'])\n",
    "existing_gen_units['pm25rate_imputed'] = existing_gen_units['pm25_rate'].combine_first(existing_gen_units['pm25rate_imputed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate aggregate emissions by multiplying rates by model-output specified generation.  As mentioned earlier, I calculate generator level generation either by calculating a generator's share of total capacity or net generation for that cluster-planningyear.\n",
    "\n",
    "Start by specifying which model, scenario, and column you want outputs for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'SWITCH'\n",
    "# model = 'TEMOA'\n",
    "# model = 'GenX'\n",
    "# model = 'UNENSYS\n",
    "\n",
    "\n",
    "scenario = '26z-thin-debug'\n",
    "# scenario = '26z-debug-noCO2Cap'\n",
    "\n",
    "# column = 'NET_GEN_GENERATOR'\n",
    "column = 'capacity_mw'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = pd.read_csv(\"MIP_results_comparison/\"+scenario+\"/\"+model+\" results summary/generation.csv\")\n",
    "\n",
    "technology_year_total = existing_gen_units.groupby(['Resource', 'planning_year']).agg({column : 'sum'}).reset_index()\n",
    "technology_year_total.columns = ['Resource', 'planning_year', 'technology_total']\n",
    "\n",
    "#merge in total capacity or total net gen\n",
    "existing_gen_units = pd.merge(existing_gen_units, technology_year_total, on=['Resource', 'planning_year'], how='left')\n",
    "\n",
    "#merge in model generation\n",
    "generation = generation.rename(columns={'resource_name':'Resource'})\n",
    "existing_gen_units = pd.merge(existing_gen_units, generation, on=['Resource', 'planning_year'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_gen_units['pct_total']=existing_gen_units[column]/existing_gen_units['technology_total']\n",
    "existing_gen_units['predicted_gen']=existing_gen_units['value']*existing_gen_units['pct_total']\n",
    "\n",
    "#switch to kg\n",
    "existing_gen_units['nox_predicted']=existing_gen_units['predicted_gen']*existing_gen_units['noxrate_imputed']*2.20462\n",
    "existing_gen_units['so2_predicted']=existing_gen_units['predicted_gen']*existing_gen_units['so2rate_imputed']*2.20462\n",
    "existing_gen_units['pm25_predicted']=existing_gen_units['predicted_gen']*existing_gen_units['pm25rate_imputed']*2.20462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge in plant locations\n",
    "plants = pd.read_excel('Data/eia860/2___Plant_Y2017.xlsx', skiprows=1)\n",
    "plants = plants[['Plant Code', 'Longitude', 'Latitude']]\n",
    "plants.columns = ['EIA_PLANT_ID', 'Longitude', 'Latitude']\n",
    "\n",
    "existing_gen_units = pd.merge(existing_gen_units, plants, on=['EIA_PLANT_ID'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_gen_units = existing_gen_units[['EIA_PLANT_ID', 'EIA_GENERATOR_ID', 'Resource','planning_year', 'capacity_mw', 'Longitude', 'Latitude', 'predicted_gen', 'nox_predicted', 'so2_predicted', 'pm25_predicted', 'noxrate_imputed', 'so2rate_imputed', 'pm25rate_imputed']]\n",
    "filename = 'InMap/MIP_Emissions/'+scenario+'/'+model+'/predicted_emissions.csv'\n",
    "existing_gen_units.to_csv(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split the emissions output by planning year and write to shapefiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "## 2030\n",
    "#####\n",
    "\n",
    "emissions_2030 = existing_gen_units.query('planning_year==2030')\n",
    "\n",
    "emissions_2030 = emissions_2030[['Longitude', 'Latitude', 'nox_predicted', 'so2_predicted', 'pm25_predicted']]\n",
    "emissions_2030.columns = ['Longitude', 'Latitude', 'NOx', 'SOx', 'PM2_5']\n",
    "\n",
    "emissions_2030 = geopandas.GeoDataFrame(\n",
    "    emissions_2030, geometry = geopandas.points_from_xy(emissions_2030.Longitude, emissions_2030.Latitude), crs='EPSG:4326')\n",
    "\n",
    "emissions_2030.to_file(filename='InMap/MIP_Emissions/'+scenario+'/'+model+'/emissions_2030.shp')\n",
    "\n",
    "#####\n",
    "## 2040\n",
    "#####\n",
    "\n",
    "emissions_2040 = existing_gen_units.query('planning_year==2040')\n",
    "\n",
    "emissions_2040 = emissions_2040[['Longitude', 'Latitude', 'nox_predicted', 'so2_predicted', 'pm25_predicted']]\n",
    "emissions_2040.columns = ['Longitude', 'Latitude', 'NOx', 'SOx', 'PM2_5']\n",
    "\n",
    "emissions_2040 = geopandas.GeoDataFrame(\n",
    "    emissions_2040, geometry = geopandas.points_from_xy(emissions_2040.Longitude, emissions_2040.Latitude), crs='EPSG:4326')\n",
    "\n",
    "emissions_2040.to_file(filename='InMap/MIP_Emissions/'+scenario+'/'+model+'/emissions_2040.shp')\n",
    "\n",
    "#####\n",
    "## 2050\n",
    "#####\n",
    "\n",
    "emissions_2050 = existing_gen_units.query('planning_year==2050')\n",
    "\n",
    "emissions_2050 = emissions_2050[['Longitude', 'Latitude', 'nox_predicted', 'so2_predicted', 'pm25_predicted']]\n",
    "emissions_2050.columns = ['Longitude', 'Latitude', 'NOx', 'SOx', 'PM2_5']\n",
    "\n",
    "emissions_2050 = geopandas.GeoDataFrame(\n",
    "    emissions_2050, geometry = geopandas.points_from_xy(emissions_2050.Longitude, emissions_2050.Latitude), crs='EPSG:4326')\n",
    "\n",
    "emissions_2050.to_file(filename='InMap/MIP_Emissions/'+scenario+'/'+model+'/emissions_2050.shp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of open questions\n",
    "\n",
    "1. What do I do about generators with negative net gen?  This makes emissions rates negative but if I just call them zero I'd be biasing plant-level emissions upwards.\n",
    "2. Do we care about stack height? \n",
    "3. When to interpolate?  Can interpolate generation but then we'd need to run the pollution model a bunch.  Could also interpolate air concentrations -- leaning towards this.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "powergenome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
